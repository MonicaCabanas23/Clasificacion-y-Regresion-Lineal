{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccc47c6-3f68-45f3-b839-5c4c8a32bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8b477d-7b92-4c7c-a8e0-8d99bfc4fe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/diabetes_012_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b347e-f24d-4c6f-a7e1-1864dbeadce5",
   "metadata": {},
   "source": [
    "1. Flujo de Entrenamiento:\n",
    "    * Cross Validation\n",
    "    * Boostrapping\n",
    "    * Whole Training Dataset\n",
    "\n",
    "2. Test - Predict\n",
    "3. Model EValuation\n",
    "    * Graphs\n",
    "    * Kruskal Wallis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2771b7b-718e-4255-9367-4b71f4f5b437",
   "metadata": {},
   "source": [
    "## Esquema de entrenamiento\n",
    "\n",
    "Para el entrenamiento de los diferentes modelos de clasificación a emplear, se seguirá el siguiente flujo de entrenamiento: \n",
    "\n",
    "1. **Se separan los datos en dos grupos**: Un bloque de datos será destinado para el entrenamiento de los modelos y otro para su evaluación, en una distribución de 75/25. Donde los datos que sean empleados para entrenar el modelo no serán los mismos que los empleados para poder evaluarlo, evitando de esta forma brindar conclusiones únicamente de datos ya previamente conocidos por los diferentes clasificadores. Por ende, ninguno de los datos presentes en el bloque de entrenamiento será empleado en el set de datos empleados para la evaluación de los modelos.\n",
    "2. **Stratified K-Fold Cross Validation**: Se dividirán los datos de entrenamiento en diferentes particiones para poder entrenar el modelo, evitar una sobredependencia en los datos ya vistos y evitar de esta forma que los modelos se sobreajusten (*over-fitting*) a la información y tengan un muy buen rendimiento aparente en datos conocidos pero al momento de agregar o probar con nueva información este sea incapaz de procesarla o lo haga con resultados pobres.\n",
    "\n",
    "    Se empleará la variente de Particiones Estratificadas o Stratified K-Fold, debido a que se esta trabajando con un conjunto de datos desbalanceado, donde además de ser múlticlase, las clases se encuentran distribuidas de forma desigual. En este caso, como se mencionó anteriormente, existe una sobre-representación por parte de los pacientes saludables en comparación con los diabéticos y los pre-diabéticos, y si no se toman medidas para poder ajustar los modelos a estas variaciones en las representaciones de los datos, se podría caer en casos donde las particiones de datos no contengan datos de alguna de las clases menos representadas, afectando el entrenamiento del modelo.\n",
    "\n",
    "3. **Bootstrapping**: Acto seguido, se empleará Bootstrapping para entrenar el modelo en esta ocasión con valores los cuales pueden repetirse entre las diferentes muestras, dad la naturaleza del muestro con repetición, para validar que los resultados se mantienen consistentes al momento de realizar las clasificaciones, además de poder reducir el sesgo que podría producirse dado el caso de emplear particiones únicas.\n",
    "\n",
    "4. **Entrenamiento completo en set de entrenamiento**: Finalmente, se entrenará el modelo en el grupo de entrenamiento completo, como última validación de métricas sin los cambios establecidos por la separación y estratificación o la repetición de datos, además de poder medir el tiempo completo que le tomaría al modelo entrenarse en el tamaño del set de datos.\n",
    "\n",
    "De cada uno estos pasos se obtendran métricas del entrenamiento como referencia base para el contraste con el set de datos de evaluación del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4624a-4e8f-4205-87fe-4527d7913d47",
   "metadata": {},
   "source": [
    "### Separación de los datos en grupos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61a254c7-4549-478e-8eec-c43a1599595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separando datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a9d763-5f1e-4a1c-9aad-3d3cd927ab4c",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "\n",
    "A continuación se utilizará el proceso de cross-validation para evaluar cuál modelo tendrá un mejor rendimiento frente a datos desconocidos. Se tomará la decisión partir de la exactitud promedio que tenga cada modelo, es decir, qué tan frecuentemente cada modelo clasifica correctamente en los pliegues de validación.\n",
    "\n",
    "Dado que los datos se encuentran desbalanceados: la clase de pacientes sanos está sobrerepresentada en comparación con los pacientes pre-diabéticos, y los diabéticos; se ha optado utilizar un muestreo estratificado, con el cual se preservará las proporciones de clases en cada pliegue de entrenamiento.\n",
    "\n",
    "Para este caso se utilizará el iterador <a href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold\">Stratified k-fold</a> de la librería scikit-learn utilizando los siguientes parámetros:\n",
    "- *<b>n_splits</b>*: Indica el número k de veces que se separará los datos en diferentes \"folds\" siendo k-1 folds los utilizados para el entrenamiento y el último para validación. En otras palabras, se puede entrenar k veces al modelo utilizando en cada iteración diferentes sets de entrenamiento y de validación.\n",
    "- *<b>shuffle</b>*: Indica si el set de datos se reordenará de manera aleatoria antes de realizar la separación. Esto es de utilidad para evitar que se genere un sesgo debido al orden de los datos.\n",
    "- *<b>random_state</b>*: Para que los resultados sean reproducibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2923c1d7-1cbf-4b11-b98f-76f26bda7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "\n",
    "# Iterador para validación cruzada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Función para obtener los scores de validación cruzada\n",
    "def get_cv_scores(model, X, y, cv):\n",
    "    # Lista de métricas de evaluación\n",
    "    scoring = ['accuracy', 'f1_macro', 'recall_macro', 'roc_auc_ovr']\n",
    "\n",
    "    results = cross_validate(model, X, y, cv=cv, scoring=scoring, return_train_score=True, error_score='raise')\n",
    "    \n",
    "    scores = {}\n",
    "    # Mostrar resultados\n",
    "    for metric in scoring:\n",
    "        scores[metric] = results['test_' + metric]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4167a-1cc3-478c-8e4c-4bfad70d82c3",
   "metadata": {},
   "source": [
    "Además, se gráficara cada una de las métricas obtenidas, mostrando lo siguiente: \n",
    "\n",
    "* El eje *x* o u horizontal mostrará el rango ajustado a los valores obtenidos a lo largo de las pruebas con cada una de las particiones.\n",
    "* El eje *y* o vertical mostrará la frecuencia con que dicho valor ha aparecido a lo largo del entrenamiento\n",
    "* La linea que divide el gráfico de forma vertical marcará la media obtenida del indicador en cuestión, su valor también aparecerá en la leyenda del gráfico para facilitar su interpretación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a34c055-9390-4d70-b4b4-466d489f5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar la distribución de los scores de exactitud\n",
    "def graph_cv_scores(accuracy_scores, mean_score, metric_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(accuracy_scores, kde=True, bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "    # Añadir líneas para los percentiles del 95% de IC\n",
    "    plt.axvline(mean_score, color='black', linestyle='-', label=f'Mean: {mean_score:.4f}')\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    plt.title(f\"Distribución de los Scores de {metric_name} (cross-validation)\", fontsize=16)\n",
    "    plt.xlabel(f\"{metric_name}\", fontsize=14)\n",
    "    plt.ylabel(\"Frecuencia\", fontsize=14)\n",
    "\n",
    "    # Leyenda\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar la gráfica\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e466eb7a-bfb4-4ade-8332-81e1a5b80b6c",
   "metadata": {},
   "source": [
    "### Métricas y generación de intervalos de confianza con bootstrap\n",
    "\n",
    "A continuación se generan los intérvalos de confianza para cada modelo mediante el método de bootstrap. El método de bootstrap consiste en el remuestreo para estimar métricas en una población a partir de muestras con reemplazo del set de datos disponible.\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "1. De un set de datos grandes se crea una muestra con datos que pueden ser repetidos. Por ejemplo, de un set de 100 datos se toma una muestra de 80 datos, se escoge el dato en la posición i, sin embargo no se elimina de la fuente de datos por lo cual puede volver a ser escogido.\n",
    "2. Una vez hecha la muestra, se obtiene la métrica de interés de esta. Por ejemplo, si es de interés obtener la media de la población, se obtendría la media de la muestra y se guarda.\n",
    "3. Se repiten los pasos 1 y 2 hasta un número de iteraciones predefinido.\n",
    "4. Una vez obtenidas las métricas para cada muestra, se saca el promedio de las métricas.\n",
    "\n",
    "#### ¿Cómo se aplica en un modelo de aprendizaje automático?\n",
    "Se repiten exactamente los mismos pasos mencionados anteriormente, sin embargo, se debe tomar en cuenta la siguiente variación: \n",
    "- Para el entrenamiento del modelo se utiliza la totalidad de los datos dentro de la muestra, sin embargo, para la evaluación del modelo se debe apartar otro set de datos conocido como out-of-bag u oob.\n",
    "\n",
    "#### ¿Cómo calcular los intervalos de confianza?\n",
    "Para obtener los intérvalos de confianza se define un nivel de confianza, por ejemplo: 95%; y se calculan los percentiles dentro de las métricas obtenidas a partir de bootstrap. Los percentiles obtenidos representan los límites inferior y superior del intérvalo. Por ejemplo, si se escoge un nivel de confianza del 95% y se obtienen los siguientes límites del intérvalo de confianza para la métrica de exactitud: [0.84, 0.87] se puede concluir que el 95% de las veces que se ejecute ese modelo tendrá una exactitud entre 84% y 87%.\n",
    "\n",
    "#### Beneficios\n",
    "- <b>Permite medir la estabilidad del modelo:</b> Cuando se realiza submuestreo bootstrap, se entrena y evalua el modelo en diferentes subconjuntos de datos. Esto permite ver cómo varía la métrica del modelo cuando se entrena en diferentes muestras de datos. Si el intervalo de confianza es estrecho, significa que la métrica del modelo es bastante estable, lo cual es deseable. Si es amplio, indica que el modelo puede estar siendo sensible a variaciones en los datos y que el rendimiento podría no ser consistente.\n",
    "- <b>Justificación de selección de modelo:</b> Si el intervalo de confianza de un modelo es mucho más estrecho o más alto en comparación con otros modelos, se puede tener una base más sólida para justificar por qué ese modelo es el mejor.\n",
    "- <b>Evaluación de la generalización del modelo:</b> El bootstrap permite evaluar cómo el modelo puede generalizar a datos no vistos, ya que se entrena con subconjuntos aleatorios de datos. Si el intervalo de confianza es relativamente pequeño y alto, indica que el modelo tiene un buen rendimiento general y puede generalizar bien, es decir, no está sobreajustado (overfitting).\n",
    "\n",
    "\n",
    "**Dentro del desarrollo del proyecto, se empleará un intervalo de confianza del 95%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cb70379-ab43-4b4b-b80b-f64bc78ce109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, f1_score\n",
    "\n",
    "# Función para obtener las métricas de evaluación y los límites del intérvalo de confianza\n",
    "def get_bootstrap_metrics_ci(n_iterations, sample_size, X, y, model):\n",
    "    # Almacenar resultados de cada métrica\n",
    "    metrics_results = {\n",
    "        \"accuracy\": [],\n",
    "        \"sensitivity\": [],  # Sensitivity = Recall para la clase positiva\n",
    "        \"auc\": [],\n",
    "        \"f1\": [],  # F1-score\n",
    "    }\n",
    "    \n",
    "    indices = np.arange(X.shape[0])\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        np.random.seed(42 + i)\n",
    "        \n",
    "        # Selección bootstrap por índices\n",
    "        bootstrap_indices = np.random.choice(indices, size=sample_size, replace=True)\n",
    "        oob_indices = np.setdiff1d(indices, bootstrap_indices)\n",
    "\n",
    "        # Conjunto bootstrap y OOB\n",
    "        X_ = X[bootstrap_indices]\n",
    "        y_ = y[bootstrap_indices]\n",
    "        oob_x = X[oob_indices]\n",
    "        oob_y = y[oob_indices]\n",
    "\n",
    "        # Entrenando modelo\n",
    "        model.fit(X_, y_)\n",
    "\n",
    "        # Predicciones\n",
    "        y_pred = model.predict(oob_x)\n",
    "\n",
    "        # Calcular métricas\n",
    "        metrics_results[\"accuracy\"].append(accuracy_score(oob_y, y_pred))\n",
    "        metrics_results[\"sensitivity\"].append(recall_score(oob_y, y_pred, average=\"macro\"))\n",
    "        metrics_results[\"f1\"].append(f1_score(oob_y, y_pred, average=\"macro\"))\n",
    "        \n",
    "        # Manejo de predict_proba para AUC multiclase\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_pred_proba = model.predict_proba(oob_x)  # Probabilidades para todas las clases\n",
    "            \n",
    "            # Calcular AUC multiclase\n",
    "            try:\n",
    "                auc_score = roc_auc_score(oob_y, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "                metrics_results[\"auc\"].append(auc_score)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error en AUC multiclase: {e}\")\n",
    "                metrics_results[\"auc\"].append(None)\n",
    "        else:\n",
    "            y_pred_proba = None\n",
    "            metrics_results[\"auc\"].append(None)\n",
    "\n",
    "    # Convertir las métricas a un DataFrame para facilidad de manejo\n",
    "    metrics_df = pd.DataFrame(metrics_results)\n",
    "    \n",
    "    # Calcular intervalos de confianza para cada métrica\n",
    "    ci_results = {}\n",
    "    for metric in metrics_results.keys():\n",
    "        ci_results[metric] = {\n",
    "            \"mean\": np.mean(metrics_df[metric]),\n",
    "            \"lower_bound\": np.percentile(metrics_df[metric].dropna(), 2.5),  # Excluye None\n",
    "            \"upper_bound\": np.percentile(metrics_df[metric].dropna(), 97.5)\n",
    "        }\n",
    "\n",
    "    return metrics_df, ci_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20311561-1614-4dcc-bd3e-cdbfe64d1ab0",
   "metadata": {},
   "source": [
    "Además, se gráficara cada una de las métricas obtenidas, al igual que en Cross Validation siguiendo un esquema muy similar, mostrando lo siguiente: \n",
    "\n",
    "* El eje *x* o u horizontal mostrará el rango ajustado a los valores obtenidos a lo largo de las pruebas con cada una de las particiones.\n",
    "* El eje *y* o vertical mostrará la frecuencia con que dicho valor ha aparecido a lo largo del entrenamiento\n",
    "* La linea que divide el gráfico de forma vertical marcará la media obtenida del indicador en cuestión, su valor también aparecerá en la leyenda del gráfico para facilitar su interpretación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0095c17-1931-4043-b621-727b6940d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar la distribución de los scores de exactitud\n",
    "def graph_bootstrap_ci(accuracy_scores, lower_bound, upper_bound, mean_score, metric_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(accuracy_scores, kde=True, bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "    # Añadir líneas para los percentiles del 95% de IC\n",
    "    plt.axvline(lower_bound, color='red', linestyle='--', label=f'2.5% Percentile: {lower_bound:.4f}')\n",
    "    plt.axvline(upper_bound, color='green', linestyle='--', label=f'97.5% Percentile: {upper_bound:.4f}')\n",
    "    plt.axvline(mean_score, color='black', linestyle='-', label=f'Mean: {mean_score:.4f}')\n",
    "    \n",
    "    # Etiquetas y título\n",
    "    plt.title(f\"Distribución de los Scores de {metric_name} (Bootstrap)\", fontsize=16)\n",
    "    plt.xlabel(f\"{metric_name}\", fontsize=14)\n",
    "    plt.ylabel(\"Frecuencia\", fontsize=14)\n",
    "\n",
    "    # Leyenda\n",
    "    plt.legend()\n",
    "\n",
    "    # Mostrar la gráfica\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46182648-b0d8-45be-94ab-9a0145d21abe",
   "metadata": {},
   "source": [
    "## Esquema de Prueba de Funcionamiento del modelo\n",
    "\n",
    "Para poder evaluar el resultado final del entrenamiento de cada uno de los modelos y obtener métricas reales del funcionamiento del modelo, estos serán entrenados con los datos reservados para evaluación, y se procederá a un análisis de las métricas obtenidas por los modelos para poder determinar cual sería el mejor a seleccionar. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
